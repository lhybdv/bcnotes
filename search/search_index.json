{
    "config": {
        "lang": [
            "en"
        ],
        "prebuild_index": false,
        "separator": "[\\s\\-]+"
    },
    "docs": [
        {
            "location": "",
            "text": "刘挥宇的区块链学习笔记 ¶",
            "title": "刘挥宇的区块链学习笔记"
        },
        {
            "location": "#_1",
            "text": "",
            "title": "刘挥宇的区块链学习笔记"
        },
        {
            "location": "bitcoin/QA/",
            "text": "Q & A ¶ \b挖矿节点为什么需要是全节点? 矿池架构下，挖矿节点可以不是全节点; \b单节点挖矿需要是全节点。 \b交易中\b的 \"交易输入\" 未必来自很新的块。链中相邻的两个块中的交易可以没有任何联系，它们只是从保存的角度上 \"物理相邻\"，\b只表达后继块对前驱块 \"合法性\" 的认可。所以，节点在收到 \"新交易\" 的\b时候，这个交易的 \"交易输入\" \b有可能来自于链中的任何位置，本地若只保存 \"\b一部分区块\"，是无法覆盖的。 \"交易输入\" 中包含 previous_output_hash 从而能够找到前置交易，但并不包含交易内容 (减小传输量) 但如果本地没有该交易所在区块，势必要从其他节点下载，这样的性能会降低 \"挖矿节点\" 挖矿成功率。 矿池架构下的 \"挖矿节点\" 可以从 \"中继节点\" 获取交易信息，从而不必是全节点 \"SPV 验证\"，只关心跟自己地址相关的交易，量小，并且不存在 \"速度\" 上的竞争，\"挖矿\" 面对整个网络，且越快越好。",
            "title": "QA"
        },
        {
            "location": "bitcoin/QA/#q-a",
            "text": "\b挖矿节点为什么需要是全节点? 矿池架构下，挖矿节点可以不是全节点; \b单节点挖矿需要是全节点。 \b交易中\b的 \"交易输入\" 未必来自很新的块。链中相邻的两个块中的交易可以没有任何联系，它们只是从保存的角度上 \"物理相邻\"，\b只表达后继块对前驱块 \"合法性\" 的认可。所以，节点在收到 \"新交易\" 的\b时候，这个交易的 \"交易输入\" \b有可能来自于链中的任何位置，本地若只保存 \"\b一部分区块\"，是无法覆盖的。 \"交易输入\" 中包含 previous_output_hash 从而能够找到前置交易，但并不包含交易内容 (减小传输量) 但如果本地没有该交易所在区块，势必要从其他节点下载，这样的性能会降低 \"挖矿节点\" 挖矿成功率。 矿池架构下的 \"挖矿节点\" 可以从 \"中继节点\" 获取交易信息，从而不必是全节点 \"SPV 验证\"，只关心跟自己地址相关的交易，量小，并且不存在 \"速度\" 上的竞争，\"挖矿\" 面对整个网络，且越快越好。",
            "title": "Q &amp; A"
        },
        {
            "location": "bitcoin/protocal/",
            "text": "比特币通信协议 ¶ 1 共用结构 ¶ 1.1 Message(消息) ¶ 字段尺寸 描述 数据类型 说明 4 magic uint32_t 用于识别消息的来源网络，当流状态位置时，它还用于寻找下一条消息 12 command char[12] 识别包内容的ASCII字串，用NULL字符补满，(使用非NULL字符填充会被拒绝) 4 length uint32_t payload的字节数 4 checksum uint32_t sha256(sha256(payload)) 的前4个字节(不包含在version 或 verack 中) ? payload uchar[] 实际数据 command char 范围 [-128, 127], 第 1 位表示符号，0 为正，1 为负 uchar[] 范围 [0, 255] command 就是消息的类型，目前涉及的类型有： version verack addr inv getdata getblocks getheaders tx block headers getaddr ping alert merkleblock mempool pong notfound filterload filteradd filterclear reject sendheaders feefilter sendcmpct cmpctblock getblocktxn blocktxn Note 对 payload (消息体) 的 2 次 sha256 哈希之后的前 4 个字节，跟 git 用法类似，前几位足以起到区别的作用 应该 不是 用于防恶意篡改的，因为发出方自己可以重新计算，同时改 payload 和 checksum 应该 是 防止网络传输、读取错误之类的导致数据不完整 version, verack 这 2 个消息没有 checksum，因为没有 payload 已定义的magic值： Network Magic value Sent over wire as main 0xD9B4BEF9 F9 BE B4 D9 testnet 0xDAB5BFFA FA BF B5 DA testnet3 0x0709110B 0B 11 09 07 namecoin 0xFEB4BEF9 F9 BE B4 FE 1.2.1.2 Variable length integer (变长整数) ¶ 值 存储长度 格式 < 0xfd 1 uint8_t <= 0xffff 3 0xfd + uint16_t <= 0xffffffff 5 0xfe + uint32_t - 9 0xff + uint64_t 1.2.1.3 Variable length string (变长字符串) ¶ 字段尺寸 描述 数据类型 说明 ? length var_int 字符串长度 ? string char[] 字符串本身(可为空) 1.2.1.4 Network address (网络地址) ¶ 字段尺寸 描述 数据类型 说明 8 services uint64_t 与version 消息中的service(s)相同 16 IPv6/4 char[16] Ipv6地址，以网络字节顺序存储。 2 port uint16_t 端口号，以网络字节顺序存储。 Note 官方客户端仅支持IPv4，仅读取最后4个字节以获取IPv4地址。 IPv4地址以16字节的IPv4映射位址格式写入结构。(12字节 00 00 00 00 00 00 00 00 00 00 FF FF, 后跟4 字节IPv4地址) 1.2.1.5 Inventory Vectors (清单向量) ¶ 字段尺寸 描述 数据类型 说明 4 type uint32_t 对象类型标识 32 hash char[32] 对象散列值 目前对象类型标识已经定义如下3个值 Value Name Description 0 ERROR Any data of with this number may be ignored 1 MSG_TX Hash is related to a transaction 2 MSG_BLOCK Hash is related to a data block 3 MSG_FILTERED_BLOCK Hash of a block header; identical to MSG_BLOCK. Only to be used in getdata message. Indicates the reply should be a merkleblock message rather than a block message; this only works if a bloom filter has been set. 4 MSG_CMPCT_BLOCK Hash of a block header; identical to MSG_BLOCK. Only to be used in getdata message. Indicates the reply should be a cmpctblock message. See BIP 152 for more info. 1.2.1.6 Block Headers (Block头部) ¶ 字段尺寸 描述 数据类型 说明 4 version uint32_t Block版本信息，基于创建该block的软件版本 32 prev_block char[32] 该block前一block的散列 32 merkle_root char[32] 与该block相关的全部交易之散列(Merkle树) 4 timestamp uint32_t 记录block创建时间的时间戳 4 bits uint32_t 创建block的计算难度 4 nonce uint32_t 用于生成block的临时数据 1 txn_count uint8_t 交易数，这个值总是0 2 消息类型 ¶ 2.1 version ¶ 一个节点收到连接请求时，它立即宣告其版本。在通信双方都得到对方版本之前，不会有其他通信 字段尺寸 描述 数据类型 说明 4 version uint32_t 节点使用的协议版本标识 8 services uint64_t 该连接允许的特性(bitfield) 8 timestamp uint64_t 以秒计算的标准UNIX时间戳 26 addr_me net_addr 生成此消息的节点的网络地址 version >= 106 26 addr_you net_addr 接收此消息的节点的网络地址 8 nonce uint64_t 节点的随机id，用于侦测这个连接 ? sub_version_num var_str 辅助版本信息 version >= 209 4 start_height uint32_t 发送节点接收到的最新block 2.2 verack ¶ 版本不低于209的客户端在应答version消息时发送verack消息 2.3 addr ¶ 字段尺寸 描述 数据类型 说明 1+ count var_int 地址数 30x? addr_list (uint32_t + net_addr)[] 网络上其他节点的地址，版本低于209时仅读取第一条 2.4 inv ¶ 字段尺寸 描述 数据类型 说明 ? count var_int 清单(inventory)数量 36x? inventory inv_vect[] 清单(inventory)数据 2.5 getdata ¶ 字段尺寸 描述 数据类型 说明 ? count var_int 清单(inventory)数量 36x? inventory inv_vect[] 清单(inventory)数据 2.6 getblocks ¶ 字段尺寸 描述 数据类型 说明 1+ start count var_int hash_start 的数量 32+ hash_start char[32] 发送节点已知的最新block散列 32 hash_stop char[32] 请求的最后一个block的散列，若要获得尽可能多的block则设为0 2.7 getheaders ¶ 字段尺寸 描述 数据类型 说明 1+ start count var_int hash_start 的数量 32+ hash_start char[32] 发送节点已知的最新block散列 32 hash_stop char[32] 请求的最后一个block的散列，若要获得尽可能多的block则设为0 2.8 tx ¶ 字段尺寸 描述 数据类型 说明 4 version uint32_t 交易数据格式版本 1+ tx_in count var_int 交易的输入数 41+ tx_in tx_in[] 交易输入或比特币来源列表 1+ tx_out count var_int 交易的输出数 8+ tx_out tx_out[] 交易输出或比特币去向列表 4 lock_time uint32_t 锁定交易的期限或block数目。如果为0则交易一直被锁定。未锁定的交易不可包含在block中，并可以在过期前修改(目前bitcon不允许更改交易，所以没有用) tx_in 字段尺寸 描述 数据类型 说明 36 previous_output outpoint 对前一输出的引用 1+ script length var_int signature script 的长度 ? signature script uchar[] 用于确认交易授权的计算脚本 4 sequence uint32_t 发送者定义的交易版本，用于在交易被写入block之前更改交易 outPoint 字段尺寸 描述 数据类型 说明 32 hash char[32] 引用的交易的散列 4 index uint32_t 指定输出的索引，第一笔输出的索引是0，以此类推 tx_out 字段尺寸 描述 数据类型 说明 8 value uint64_t 交易的比特币数量(单位是0.00000001) 1+ pk_script length var_int pk_script的长度 ? pk_script uchar[] Usually contains the public key as a Bitcoin script setting up conditions to claim this output. 2.9 block ¶ 字段尺寸 描述 数据类型 说明 4 version uint32_t block版本信息，基于生成block的软件版本 32 prev_block char[32] 这一block引用的前一block之散列 32 merkle_root char[32] 与这一block相关的全部交易之散列(Merkle树) 4 timestamp uint32_t 记录block创建时间的时间戳 4 bits uint32_t 这一block的计算难度 4 nonce uint32_t 用于生成这一block的nonce值 ? txn_count var_int 交易数量 ? txns tx[] 交易，以tx格式存储 2.10 headers ¶ 字段尺寸 描述 数据类型 说明 ? count var_int block头数量 77x? headers block_header[] block头 2.11 getaddr ¶ !!! question getaddr 似乎也没有消息体? 2.12 checkorder ¶ 字段尺寸 描述 数据类型 说明 Fields from CMerkleTx ? hashBlock ? vMerkleBranch ? nIndex Fields from CWalletTx ? vtxPrev ? mapValue ? vOrderForm ? fTimeReceivedIsTxTime ? nTimeReceived ? fFromMe ? fSpent 2.13 submitorder ¶ 字段尺寸 描述 数据类型 说明 32 hash char[32] 交易散列 ? wallet_entry CWalletTx 与checkorder的payload相同 2.14 reply ¶ 字段尺寸 描述 数据类型 说明 4 reply uint32_t 应答代码 可能值: 值 名称 说明 0 SUCCESS IP Transaction可以执行(回应checkorder)或已经被接受(回应submitorder) 1 WALLET_ERROR AcceptWalletTransaction()失败 2 DENIED 此节点不接受IP Transactions 2.15 ping ¶ 2.16 alert ¶ 字段尺寸 描述 数据类型 说明 ? message var_str 向网络中所有节点发出的系统消息 ? signature var_str 可由公钥验证Satoshi授权或创建了此信息的签名",
            "title": "通信协议"
        },
        {
            "location": "bitcoin/protocal/#_1",
            "text": "",
            "title": "比特币通信协议"
        },
        {
            "location": "bitcoin/protocal/#1",
            "text": "",
            "title": "1 共用结构"
        },
        {
            "location": "bitcoin/protocal/#11-message",
            "text": "字段尺寸 描述 数据类型 说明 4 magic uint32_t 用于识别消息的来源网络，当流状态位置时，它还用于寻找下一条消息 12 command char[12] 识别包内容的ASCII字串，用NULL字符补满，(使用非NULL字符填充会被拒绝) 4 length uint32_t payload的字节数 4 checksum uint32_t sha256(sha256(payload)) 的前4个字节(不包含在version 或 verack 中) ? payload uchar[] 实际数据 command char 范围 [-128, 127], 第 1 位表示符号，0 为正，1 为负 uchar[] 范围 [0, 255] command 就是消息的类型，目前涉及的类型有： version verack addr inv getdata getblocks getheaders tx block headers getaddr ping alert merkleblock mempool pong notfound filterload filteradd filterclear reject sendheaders feefilter sendcmpct cmpctblock getblocktxn blocktxn Note 对 payload (消息体) 的 2 次 sha256 哈希之后的前 4 个字节，跟 git 用法类似，前几位足以起到区别的作用 应该 不是 用于防恶意篡改的，因为发出方自己可以重新计算，同时改 payload 和 checksum 应该 是 防止网络传输、读取错误之类的导致数据不完整 version, verack 这 2 个消息没有 checksum，因为没有 payload 已定义的magic值： Network Magic value Sent over wire as main 0xD9B4BEF9 F9 BE B4 D9 testnet 0xDAB5BFFA FA BF B5 DA testnet3 0x0709110B 0B 11 09 07 namecoin 0xFEB4BEF9 F9 BE B4 FE",
            "title": "1.1 Message(消息)"
        },
        {
            "location": "bitcoin/protocal/#1212-variable-length-integer",
            "text": "值 存储长度 格式 < 0xfd 1 uint8_t <= 0xffff 3 0xfd + uint16_t <= 0xffffffff 5 0xfe + uint32_t - 9 0xff + uint64_t",
            "title": "1.2.1.2 Variable length integer (变长整数)"
        },
        {
            "location": "bitcoin/protocal/#1213-variable-length-string",
            "text": "字段尺寸 描述 数据类型 说明 ? length var_int 字符串长度 ? string char[] 字符串本身(可为空)",
            "title": "1.2.1.3 Variable length string (变长字符串)"
        },
        {
            "location": "bitcoin/protocal/#1214-network-address",
            "text": "字段尺寸 描述 数据类型 说明 8 services uint64_t 与version 消息中的service(s)相同 16 IPv6/4 char[16] Ipv6地址，以网络字节顺序存储。 2 port uint16_t 端口号，以网络字节顺序存储。 Note 官方客户端仅支持IPv4，仅读取最后4个字节以获取IPv4地址。 IPv4地址以16字节的IPv4映射位址格式写入结构。(12字节 00 00 00 00 00 00 00 00 00 00 FF FF, 后跟4 字节IPv4地址)",
            "title": "1.2.1.4 Network address (网络地址)"
        },
        {
            "location": "bitcoin/protocal/#1215-inventory-vectors",
            "text": "字段尺寸 描述 数据类型 说明 4 type uint32_t 对象类型标识 32 hash char[32] 对象散列值 目前对象类型标识已经定义如下3个值 Value Name Description 0 ERROR Any data of with this number may be ignored 1 MSG_TX Hash is related to a transaction 2 MSG_BLOCK Hash is related to a data block 3 MSG_FILTERED_BLOCK Hash of a block header; identical to MSG_BLOCK. Only to be used in getdata message. Indicates the reply should be a merkleblock message rather than a block message; this only works if a bloom filter has been set. 4 MSG_CMPCT_BLOCK Hash of a block header; identical to MSG_BLOCK. Only to be used in getdata message. Indicates the reply should be a cmpctblock message. See BIP 152 for more info.",
            "title": "1.2.1.5 Inventory Vectors (清单向量)"
        },
        {
            "location": "bitcoin/protocal/#1216-block-headers-block",
            "text": "字段尺寸 描述 数据类型 说明 4 version uint32_t Block版本信息，基于创建该block的软件版本 32 prev_block char[32] 该block前一block的散列 32 merkle_root char[32] 与该block相关的全部交易之散列(Merkle树) 4 timestamp uint32_t 记录block创建时间的时间戳 4 bits uint32_t 创建block的计算难度 4 nonce uint32_t 用于生成block的临时数据 1 txn_count uint8_t 交易数，这个值总是0",
            "title": "1.2.1.6 Block Headers (Block头部)"
        },
        {
            "location": "bitcoin/protocal/#2",
            "text": "",
            "title": "2 消息类型"
        },
        {
            "location": "bitcoin/protocal/#21-version",
            "text": "一个节点收到连接请求时，它立即宣告其版本。在通信双方都得到对方版本之前，不会有其他通信 字段尺寸 描述 数据类型 说明 4 version uint32_t 节点使用的协议版本标识 8 services uint64_t 该连接允许的特性(bitfield) 8 timestamp uint64_t 以秒计算的标准UNIX时间戳 26 addr_me net_addr 生成此消息的节点的网络地址 version >= 106 26 addr_you net_addr 接收此消息的节点的网络地址 8 nonce uint64_t 节点的随机id，用于侦测这个连接 ? sub_version_num var_str 辅助版本信息 version >= 209 4 start_height uint32_t 发送节点接收到的最新block",
            "title": "2.1 version"
        },
        {
            "location": "bitcoin/protocal/#22-verack",
            "text": "版本不低于209的客户端在应答version消息时发送verack消息",
            "title": "2.2 verack"
        },
        {
            "location": "bitcoin/protocal/#23-addr",
            "text": "字段尺寸 描述 数据类型 说明 1+ count var_int 地址数 30x? addr_list (uint32_t + net_addr)[] 网络上其他节点的地址，版本低于209时仅读取第一条",
            "title": "2.3 addr"
        },
        {
            "location": "bitcoin/protocal/#24-inv",
            "text": "字段尺寸 描述 数据类型 说明 ? count var_int 清单(inventory)数量 36x? inventory inv_vect[] 清单(inventory)数据",
            "title": "2.4 inv"
        },
        {
            "location": "bitcoin/protocal/#25-getdata",
            "text": "字段尺寸 描述 数据类型 说明 ? count var_int 清单(inventory)数量 36x? inventory inv_vect[] 清单(inventory)数据",
            "title": "2.5 getdata"
        },
        {
            "location": "bitcoin/protocal/#26-getblocks",
            "text": "字段尺寸 描述 数据类型 说明 1+ start count var_int hash_start 的数量 32+ hash_start char[32] 发送节点已知的最新block散列 32 hash_stop char[32] 请求的最后一个block的散列，若要获得尽可能多的block则设为0",
            "title": "2.6 getblocks"
        },
        {
            "location": "bitcoin/protocal/#27-getheaders",
            "text": "字段尺寸 描述 数据类型 说明 1+ start count var_int hash_start 的数量 32+ hash_start char[32] 发送节点已知的最新block散列 32 hash_stop char[32] 请求的最后一个block的散列，若要获得尽可能多的block则设为0",
            "title": "2.7 getheaders"
        },
        {
            "location": "bitcoin/protocal/#28-tx",
            "text": "字段尺寸 描述 数据类型 说明 4 version uint32_t 交易数据格式版本 1+ tx_in count var_int 交易的输入数 41+ tx_in tx_in[] 交易输入或比特币来源列表 1+ tx_out count var_int 交易的输出数 8+ tx_out tx_out[] 交易输出或比特币去向列表 4 lock_time uint32_t 锁定交易的期限或block数目。如果为0则交易一直被锁定。未锁定的交易不可包含在block中，并可以在过期前修改(目前bitcon不允许更改交易，所以没有用) tx_in 字段尺寸 描述 数据类型 说明 36 previous_output outpoint 对前一输出的引用 1+ script length var_int signature script 的长度 ? signature script uchar[] 用于确认交易授权的计算脚本 4 sequence uint32_t 发送者定义的交易版本，用于在交易被写入block之前更改交易 outPoint 字段尺寸 描述 数据类型 说明 32 hash char[32] 引用的交易的散列 4 index uint32_t 指定输出的索引，第一笔输出的索引是0，以此类推 tx_out 字段尺寸 描述 数据类型 说明 8 value uint64_t 交易的比特币数量(单位是0.00000001) 1+ pk_script length var_int pk_script的长度 ? pk_script uchar[] Usually contains the public key as a Bitcoin script setting up conditions to claim this output.",
            "title": "2.8 tx"
        },
        {
            "location": "bitcoin/protocal/#29-block",
            "text": "字段尺寸 描述 数据类型 说明 4 version uint32_t block版本信息，基于生成block的软件版本 32 prev_block char[32] 这一block引用的前一block之散列 32 merkle_root char[32] 与这一block相关的全部交易之散列(Merkle树) 4 timestamp uint32_t 记录block创建时间的时间戳 4 bits uint32_t 这一block的计算难度 4 nonce uint32_t 用于生成这一block的nonce值 ? txn_count var_int 交易数量 ? txns tx[] 交易，以tx格式存储",
            "title": "2.9 block"
        },
        {
            "location": "bitcoin/protocal/#210-headers",
            "text": "字段尺寸 描述 数据类型 说明 ? count var_int block头数量 77x? headers block_header[] block头",
            "title": "2.10 headers"
        },
        {
            "location": "bitcoin/protocal/#211-getaddr",
            "text": "!!! question getaddr 似乎也没有消息体?",
            "title": "2.11 getaddr"
        },
        {
            "location": "bitcoin/protocal/#212-checkorder",
            "text": "字段尺寸 描述 数据类型 说明 Fields from CMerkleTx ? hashBlock ? vMerkleBranch ? nIndex Fields from CWalletTx ? vtxPrev ? mapValue ? vOrderForm ? fTimeReceivedIsTxTime ? nTimeReceived ? fFromMe ? fSpent",
            "title": "2.12 checkorder"
        },
        {
            "location": "bitcoin/protocal/#213-submitorder",
            "text": "字段尺寸 描述 数据类型 说明 32 hash char[32] 交易散列 ? wallet_entry CWalletTx 与checkorder的payload相同",
            "title": "2.13 submitorder"
        },
        {
            "location": "bitcoin/protocal/#214-reply",
            "text": "字段尺寸 描述 数据类型 说明 4 reply uint32_t 应答代码 可能值: 值 名称 说明 0 SUCCESS IP Transaction可以执行(回应checkorder)或已经被接受(回应submitorder) 1 WALLET_ERROR AcceptWalletTransaction()失败 2 DENIED 此节点不接受IP Transactions",
            "title": "2.14 reply"
        },
        {
            "location": "bitcoin/protocal/#215-ping",
            "text": "",
            "title": "2.15 ping"
        },
        {
            "location": "bitcoin/protocal/#216-alert",
            "text": "字段尺寸 描述 数据类型 说明 ? message var_str 向网络中所有节点发出的系统消息 ? signature var_str 可由公钥验证Satoshi授权或创建了此信息的签名",
            "title": "2.16 alert"
        },
        {
            "location": "bitcoin/structure/",
            "text": "\b比特币数据结构 ¶ 1. 区块存储 ¶ blocks/blk*.dat 的文件中存储了实际的块数据，这些数据以网络格式存储。它们仅用于重新扫描钱包中丢失的交易，将这些交易重新组织到链的不同部分，并将数据块提供给其他正在同步数据的节点。 blocks/index/* 是一个levelDB数据库，存储着目前已知块的元数据，这些元数据记录所有已知的块以及它们存储在磁盘上的位置。没有这些文件，查找一个块将是非常慢的。 chainstate/* 是一个levelDB数据库，以紧凑的形式存储所有当前未花费的交易以及它们的元数据。这里的数据对于验证新传入的块和交易是必要的。在理论上，这些数据可以从块数据中重建，但是这需要很长时间。没有这些数据也可以对数据进行验证，但是需要现有块数据进行扫面，这无疑是非常慢的。 blocks/rev*.dat 中包含了“撤销”数据，可以将区块视为链的“补丁”（它们消耗一些未花费的输出并生成新的输出），那么这些撤销数据将是反向补丁。如果需要回滚链，这些数据将是必须的。 比特币程序从网络中接受数据后，会将数据以.dat的形式转储到磁盘上。 一个块文件大约为128MB。每个块文件会有一个对应的撤销文件，比如文件blocks/blk1234.dat和blocks/recv1234.dat对应。 2. 块结构 ¶ 大小(字节) 名称 数据类型 描述 4 magic_number uint32 总是 0xD9B4BEF9, 作为区块之间的分隔符 4 block_size uint32 后面数据到块结束的字节数 80 block_header char[] block heaer varies transaction_cnt uint 交易数量 varies transaction char[] 交易详情 从原始数据中读取的流程大概如下 读取4个字节，比对 magic_number 一旦匹配，读取后4个字节，得到块的大小 m 读取后面 m 个字节，得到区块的数据 返回第一步，读取下一个区块 3. Block Header ¶ block header固定 80 字节大小，结构如下 大小(字节) 名称 数据类型 描述 4 version int32_t 版本号 32 previous_block_hash char[32] 前一个 block 的 \bhash 值 32 merkle_root_hash char[32] 区块内所有交易的 merkle_hash 值 4 time uint32 unix时间戳，矿工挖矿的时间 4 nBits unit32 该块的标题hash必须小于的值。难度 4 nonce unit32 \b随机值，用于产生满足难度的hash值 4. 交易 ¶ 大小(字节) 名称 数据类型 描述 4 version unit32 交易版本号 varint tx_in_count uint 交易输入数量 varies tx_in tx_in 交易输入 varint tx_out_count uint 交易输出数量 varies txt_out tx_out 交易输出 4 lock_time uint32 锁定时间 Note 交易中使用可变长度整数来表示下一条数据中的字节数。对于不同的数值，存储的空间不一样。 对于0～252的值，只占用一个字节；对于其他小于0xffffffffffffffff的值，第一个字节将成为长度标识位。值和存储空间的关系如下表： 值 存储空间 (字节) 数据类型 >=0 && <=252 1 uint8_t >=253 && <= 0xffff 3 \b后 2 个字节 uint16_t >=0x10000 && <= 0xffffffff 5 后 4 个字节 uint32_t >=0x100000000 && <= 0xffffffffffffffff 9 后 8 个字节uint64_t Note 就是说 若 tx_in_count 的第 1 \b字节 <= 252，那么这个字节本身就是 值 若 tx_in_count 的第 1 \b字节 = 253，那么 值 存储在后面的 2 个字节里 若 tx_in_count 的第 1 \b字节 = 254，那么 值 存储在后面的 4 个字节里 若 tx_in_count 的第 1 \b字节 = 255，那么 值 存储在后面的 8 个字节里 5. 交易输入 ¶ 每个非coinbase的交易输入都是之前某个交易的交易输出 交易输入的结构如下: 大小(字节) 名称 数据类型 描述 32 previous_output_hash outpoint 前置交易h\bash 4 previous_output_index uint32 前置交易index varint script_bytes uint 解锁脚本长度 varies signature_script char[] 解锁脚本 4 sequence uint32 序列号 6. 交易输出 ¶ 大小(字节) 名称 数据类型 描述 8 value int64 花费的数量，单位是聪 1+ pk_sript_size uint pubkey脚本中的字节数量 varies pk_script char[] 花费这笔输出需要满足的条件",
            "title": "结构"
        },
        {
            "location": "bitcoin/structure/#_1",
            "text": "",
            "title": "\b比特币数据结构"
        },
        {
            "location": "bitcoin/structure/#1",
            "text": "blocks/blk*.dat 的文件中存储了实际的块数据，这些数据以网络格式存储。它们仅用于重新扫描钱包中丢失的交易，将这些交易重新组织到链的不同部分，并将数据块提供给其他正在同步数据的节点。 blocks/index/* 是一个levelDB数据库，存储着目前已知块的元数据，这些元数据记录所有已知的块以及它们存储在磁盘上的位置。没有这些文件，查找一个块将是非常慢的。 chainstate/* 是一个levelDB数据库，以紧凑的形式存储所有当前未花费的交易以及它们的元数据。这里的数据对于验证新传入的块和交易是必要的。在理论上，这些数据可以从块数据中重建，但是这需要很长时间。没有这些数据也可以对数据进行验证，但是需要现有块数据进行扫面，这无疑是非常慢的。 blocks/rev*.dat 中包含了“撤销”数据，可以将区块视为链的“补丁”（它们消耗一些未花费的输出并生成新的输出），那么这些撤销数据将是反向补丁。如果需要回滚链，这些数据将是必须的。 比特币程序从网络中接受数据后，会将数据以.dat的形式转储到磁盘上。 一个块文件大约为128MB。每个块文件会有一个对应的撤销文件，比如文件blocks/blk1234.dat和blocks/recv1234.dat对应。",
            "title": "1. 区块存储"
        },
        {
            "location": "bitcoin/structure/#2",
            "text": "大小(字节) 名称 数据类型 描述 4 magic_number uint32 总是 0xD9B4BEF9, 作为区块之间的分隔符 4 block_size uint32 后面数据到块结束的字节数 80 block_header char[] block heaer varies transaction_cnt uint 交易数量 varies transaction char[] 交易详情 从原始数据中读取的流程大概如下 读取4个字节，比对 magic_number 一旦匹配，读取后4个字节，得到块的大小 m 读取后面 m 个字节，得到区块的数据 返回第一步，读取下一个区块",
            "title": "2. 块结构"
        },
        {
            "location": "bitcoin/structure/#3-block-header",
            "text": "block header固定 80 字节大小，结构如下 大小(字节) 名称 数据类型 描述 4 version int32_t 版本号 32 previous_block_hash char[32] 前一个 block 的 \bhash 值 32 merkle_root_hash char[32] 区块内所有交易的 merkle_hash 值 4 time uint32 unix时间戳，矿工挖矿的时间 4 nBits unit32 该块的标题hash必须小于的值。难度 4 nonce unit32 \b随机值，用于产生满足难度的hash值",
            "title": "3. Block Header"
        },
        {
            "location": "bitcoin/structure/#4",
            "text": "大小(字节) 名称 数据类型 描述 4 version unit32 交易版本号 varint tx_in_count uint 交易输入数量 varies tx_in tx_in 交易输入 varint tx_out_count uint 交易输出数量 varies txt_out tx_out 交易输出 4 lock_time uint32 锁定时间 Note 交易中使用可变长度整数来表示下一条数据中的字节数。对于不同的数值，存储的空间不一样。 对于0～252的值，只占用一个字节；对于其他小于0xffffffffffffffff的值，第一个字节将成为长度标识位。值和存储空间的关系如下表： 值 存储空间 (字节) 数据类型 >=0 && <=252 1 uint8_t >=253 && <= 0xffff 3 \b后 2 个字节 uint16_t >=0x10000 && <= 0xffffffff 5 后 4 个字节 uint32_t >=0x100000000 && <= 0xffffffffffffffff 9 后 8 个字节uint64_t Note 就是说 若 tx_in_count 的第 1 \b字节 <= 252，那么这个字节本身就是 值 若 tx_in_count 的第 1 \b字节 = 253，那么 值 存储在后面的 2 个字节里 若 tx_in_count 的第 1 \b字节 = 254，那么 值 存储在后面的 4 个字节里 若 tx_in_count 的第 1 \b字节 = 255，那么 值 存储在后面的 8 个字节里",
            "title": "4. 交易"
        },
        {
            "location": "bitcoin/structure/#5",
            "text": "每个非coinbase的交易输入都是之前某个交易的交易输出 交易输入的结构如下: 大小(字节) 名称 数据类型 描述 32 previous_output_hash outpoint 前置交易h\bash 4 previous_output_index uint32 前置交易index varint script_bytes uint 解锁脚本长度 varies signature_script char[] 解锁脚本 4 sequence uint32 序列号",
            "title": "5. 交易输入"
        },
        {
            "location": "bitcoin/structure/#6",
            "text": "大小(字节) 名称 数据类型 描述 8 value int64 花费的数量，单位是聪 1+ pk_sript_size uint pubkey脚本中的字节数量 varies pk_script char[] 花费这笔输出需要满足的条件",
            "title": "6. 交易输出"
        },
        {
            "location": "bitcoin/sync/",
            "text": "1.3 同步 ¶ 1.3.1 同步场景 ¶ 1.3.1.1 建立连接 ¶ 一个节点收到连接请求时，它立即宣告其版本，发送 version 消息。在通信双方都得到对方版本之前，不会有其他通信 版本不低于209的客户端在应答version消息时发送 verack 消息 Note 相同的 版本 意味着相同的程序 1.3.1.2 INV(MSG_BLOCK) 的发送 ¶ 挖到新的 block 从其他节点获取到新的 block，即 接收到 cmpctblock ， blocktxn , block 这三个消息，并确认之后 应答 getblocks 消息 Note 应答 getblocks 消息时，只发送 inv 消息，让请求端自己进行对比筛选，有确定需要的 block 时，请求端会发送 getdata 来获取实际的 block 的全部信息 1.3.1.3 \bgetheaders 的发送 ¶ 新节点 (主动请求) 接到 inv 消息后，意识到自己的 headers 不够新 (被动) Note 接到 getheaders 请求的节点，会以 headers 消息应答，最多 2000 个 header 请求端如果得到的应答 (headers 消息) 包含 2000 个 header，意味着 应答端可能拥有更多的 header，需要再次获取 (循环获取) 如果节点在初始化中，会忽略 getheaders 消息，因为没有能力处理 1.3.2 被动获取新 Block ¶ sequenceDiagram participant l as Local participant p as Peer p ->> l: 1: inv(msg_block) l ->> p: 2: getHeaders p -->> l: 3: headers l ->> p: 4: getData p -->> l: 5: blocks 1.3.2.1 过程描述 ¶ Peer 节点挖出了新 block，或者接受了新 block (可能是多个)，发出 inv(MSG_BLOCK) 消息 Local 节点接收到 inv(MSG_BLOCK) 消息，取出了里面的 header hash 列表，在本地进行对比，找出本地没有的 header hash 列表，发出 getheaders 消息，通过 hash_start, hash_stop 表明范围，最多 2000 条，如果要尽可能多的获取，hash_stop 设为 0 Peer 节点接到 getheaders 的消息，按要求查出来本地的 header 列表 (不只是 hash，是完整的 block header 信息)，最多 2000 条，发送给 Local 节点 Local 节点接到 headers 消息后，进行验证，如果 headers 不连续，则认为 Peer 节点恶意捣乱，会做标记。然后进行 POW 验证，包括 hash 难度是不是在增加。通过验证的 header hash 信息会写入 levelDB，其余信息在内存中保留 (此处还需确认)，如果 Peer 端返回的 headers 达到了最高值 2000 条，则继续获取 (循环获取) Local 节点根据已确认的 header 列表，发出 getdata 消息，包含一个向量清单 Peer 节点收到 getdata 消息后，会按要求从磁盘读取 block 列表，发送 block 消息给 Local 节点，这里似乎 block 消息每次只发送一个 block Local 节点收到 block 消息后，进行 merkle_tree 等一系列验证，通过验证的 block 讲写入磁盘 1.3.3 主动获取新 Block ¶ sequenceDiagram participant l as Local participant p as Peer l -> p: 2: getHeaders p --> l: 3: headers l -> p: 4: getData p --> l: 5: blocks 1.3.3.1 过程描述 ¶",
            "title": "同步"
        },
        {
            "location": "bitcoin/sync/#13",
            "text": "",
            "title": "1.3 同步"
        },
        {
            "location": "bitcoin/sync/#131",
            "text": "",
            "title": "1.3.1 同步场景"
        },
        {
            "location": "bitcoin/sync/#1311",
            "text": "一个节点收到连接请求时，它立即宣告其版本，发送 version 消息。在通信双方都得到对方版本之前，不会有其他通信 版本不低于209的客户端在应答version消息时发送 verack 消息 Note 相同的 版本 意味着相同的程序",
            "title": "1.3.1.1 建立连接"
        },
        {
            "location": "bitcoin/sync/#1312-invmsg_block",
            "text": "挖到新的 block 从其他节点获取到新的 block，即 接收到 cmpctblock ， blocktxn , block 这三个消息，并确认之后 应答 getblocks 消息 Note 应答 getblocks 消息时，只发送 inv 消息，让请求端自己进行对比筛选，有确定需要的 block 时，请求端会发送 getdata 来获取实际的 block 的全部信息",
            "title": "1.3.1.2 INV(MSG_BLOCK) 的发送"
        },
        {
            "location": "bitcoin/sync/#1313-getheaders",
            "text": "新节点 (主动请求) 接到 inv 消息后，意识到自己的 headers 不够新 (被动) Note 接到 getheaders 请求的节点，会以 headers 消息应答，最多 2000 个 header 请求端如果得到的应答 (headers 消息) 包含 2000 个 header，意味着 应答端可能拥有更多的 header，需要再次获取 (循环获取) 如果节点在初始化中，会忽略 getheaders 消息，因为没有能力处理",
            "title": "1.3.1.3 \bgetheaders 的发送"
        },
        {
            "location": "bitcoin/sync/#132-block",
            "text": "sequenceDiagram participant l as Local participant p as Peer p ->> l: 1: inv(msg_block) l ->> p: 2: getHeaders p -->> l: 3: headers l ->> p: 4: getData p -->> l: 5: blocks",
            "title": "1.3.2 被动获取新 Block"
        },
        {
            "location": "bitcoin/sync/#1321",
            "text": "Peer 节点挖出了新 block，或者接受了新 block (可能是多个)，发出 inv(MSG_BLOCK) 消息 Local 节点接收到 inv(MSG_BLOCK) 消息，取出了里面的 header hash 列表，在本地进行对比，找出本地没有的 header hash 列表，发出 getheaders 消息，通过 hash_start, hash_stop 表明范围，最多 2000 条，如果要尽可能多的获取，hash_stop 设为 0 Peer 节点接到 getheaders 的消息，按要求查出来本地的 header 列表 (不只是 hash，是完整的 block header 信息)，最多 2000 条，发送给 Local 节点 Local 节点接到 headers 消息后，进行验证，如果 headers 不连续，则认为 Peer 节点恶意捣乱，会做标记。然后进行 POW 验证，包括 hash 难度是不是在增加。通过验证的 header hash 信息会写入 levelDB，其余信息在内存中保留 (此处还需确认)，如果 Peer 端返回的 headers 达到了最高值 2000 条，则继续获取 (循环获取) Local 节点根据已确认的 header 列表，发出 getdata 消息，包含一个向量清单 Peer 节点收到 getdata 消息后，会按要求从磁盘读取 block 列表，发送 block 消息给 Local 节点，这里似乎 block 消息每次只发送一个 block Local 节点收到 block 消息后，进行 merkle_tree 等一系列验证，通过验证的 block 讲写入磁盘",
            "title": "1.3.2.1 过程描述"
        },
        {
            "location": "bitcoin/sync/#133-block",
            "text": "sequenceDiagram participant l as Local participant p as Peer l -> p: 2: getHeaders p --> l: 3: headers l -> p: 4: getData p --> l: 5: blocks",
            "title": "1.3.3 主动获取新 Block"
        },
        {
            "location": "bitcoin/sync/#1331",
            "text": "",
            "title": "1.3.3.1 过程描述"
        },
        {
            "location": "eos/structure/",
            "text": "EOS 数据结构 ¶ 字段 说明 timestamp 时间戳 producer 生产者 confirmed 生产者确认数 previous 链式结构前一个区块的id transaction_mroot 交易默克尔树根 action_mroot 动作默克尔树根 schedule_version 生产者版本排序号 new_producers 下一个生产者 header_extensions 区块头扩展字段 producer_signature 区块签名，由生产者签名 transactions 块打包交易内容，是数组结构，可以多个 block_extensions 区块扩展字段 id 当前块id block_num 当前块高度 ref_block_prefix 引用区块的区块头",
            "title": "结构"
        },
        {
            "location": "eos/structure/#eos",
            "text": "字段 说明 timestamp 时间戳 producer 生产者 confirmed 生产者确认数 previous 链式结构前一个区块的id transaction_mroot 交易默克尔树根 action_mroot 动作默克尔树根 schedule_version 生产者版本排序号 new_producers 下一个生产者 header_extensions 区块头扩展字段 producer_signature 区块签名，由生产者签名 transactions 块打包交易内容，是数组结构，可以多个 block_extensions 区块扩展字段 id 当前块id block_num 当前块高度 ref_block_prefix 引用区块的区块头",
            "title": "EOS 数据结构"
        },
        {
            "location": "ethereum/QA/",
            "text": "Q & A ¶ 叔块 叔块本身是一个合法的块，它只是 \"慢\" 了一些 叔块内部的交易不会被执行 叔块只能被包含 1 次 \b\b被打包的是叔块的 header (只是认可了块的身份，\b并不执行交易) 只能打包 0 - 2 个叔块 打包叔块的矿工可以得到 1/32 的块的标准奖励 挖出叔块的矿工按间隔层数可以得到下面表格中的奖励 间隔层数 报酬比例 报酬(Eth) 1 7/8 2.625 2 6/8 2.25 3 5/8 1.875 4 4/8 1.5 5 3/8 1.125 6 2/8 0.75 RLP 的优缺点 RLP 编码定义 类型 首字节范围 编码内容 [0x00, 0x7f]的单个字节 [0x00, 0x7f] 字节内容本身 0-55 字节长的字符串 [0x80, 0xb7] 0x80加上字符串长度，后跟字符串二进制内容 超过55个字节的字符串 [0xb8, 0xbf] 0xb7加上字符串长度的长度，后跟字符串二进制内容 0-55个字节长的列表（所有项的组合长度） [0xc0, 0xf7] 0xc0加上所有的项的RLP编码串联起来的长度得到的单个字节，后跟所有的项的RLP编码的串联组成。 列表的内容超过55字节 [0xf8, 0xff] 0xC0加上所有的项的RLP编码串联起来的长度的长度得到的单个字节，后跟所有的项的RLP编码串联起来的长度的长度，再后跟所有的项的RLP编码的串联组成 优点: 存储空间小 易于实现 缺点: 与 json 相比，RLP 没有结构，比如存了一个字符串字段，只有值，并不能判断是 \"Name\" 还是 \"Address\"，这就需要解析方，明确知道数据的结构",
            "title": "QA"
        },
        {
            "location": "ethereum/QA/#q-a",
            "text": "叔块 叔块本身是一个合法的块，它只是 \"慢\" 了一些 叔块内部的交易不会被执行 叔块只能被包含 1 次 \b\b被打包的是叔块的 header (只是认可了块的身份，\b并不执行交易) 只能打包 0 - 2 个叔块 打包叔块的矿工可以得到 1/32 的块的标准奖励 挖出叔块的矿工按间隔层数可以得到下面表格中的奖励 间隔层数 报酬比例 报酬(Eth) 1 7/8 2.625 2 6/8 2.25 3 5/8 1.875 4 4/8 1.5 5 3/8 1.125 6 2/8 0.75 RLP 的优缺点 RLP 编码定义 类型 首字节范围 编码内容 [0x00, 0x7f]的单个字节 [0x00, 0x7f] 字节内容本身 0-55 字节长的字符串 [0x80, 0xb7] 0x80加上字符串长度，后跟字符串二进制内容 超过55个字节的字符串 [0xb8, 0xbf] 0xb7加上字符串长度的长度，后跟字符串二进制内容 0-55个字节长的列表（所有项的组合长度） [0xc0, 0xf7] 0xc0加上所有的项的RLP编码串联起来的长度得到的单个字节，后跟所有的项的RLP编码的串联组成。 列表的内容超过55字节 [0xf8, 0xff] 0xC0加上所有的项的RLP编码串联起来的长度的长度得到的单个字节，后跟所有的项的RLP编码串联起来的长度的长度，再后跟所有的项的RLP编码的串联组成 优点: 存储空间小 易于实现 缺点: 与 json 相比，RLP 没有结构，比如存了一个字符串字段，只有值，并不能判断是 \"Name\" 还是 \"Address\"，这就需要解析方，明确知道数据的结构",
            "title": "Q &amp; A"
        },
        {
            "location": "ethereum/protocal/",
            "text": "以太坊协议 ¶ 1 Msg ¶ 1 2 3 4 5 6 type Msg struct { Code uint64 Size uint32 // size of the paylod Payload io . Reader ReceivedAt time . Time } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 const ( // Protocol messages belonging to eth/62 StatusMsg = 0x00 NewBlockHashesMsg = 0x01 TxMsg = 0x02 GetBlockHeadersMsg = 0x03 BlockHeadersMsg = 0x04 GetBlockBodiesMsg = 0x05 BlockBodiesMsg = 0x06 NewBlockMsg = 0x07 // Protocol messages belonging to eth/63 GetNodeDataMsg = 0x0d NodeDataMsg = 0x0e GetReceiptsMsg = 0x0f ReceiptsMsg = 0x10 ) Code 相当于 比特币 的 \"command\"，但是明显 \"Code\" 的可扩展性要好的多，但是要求必须都约定好每个数字对应的命令是什么 2 GetBlockHeaders ¶ 1 2 3 4 5 6 7 8 9 10 11 12 type getBlockHeadersData struct { Origin hashOrNumber // Block from which to retrieve headers Amount uint64 // Maximum number of headers to retrieve Skip uint64 // Blocks to skip between consecutive headers Reverse bool // Query direction (false = rising towards latest, true = falling towards genesis) } // hashOrNumber is a combined field for specifying an origin block. type hashOrNumber struct { Hash common . Hash // Block hash from which to retrieve headers (excludes Number) Number uint64 // Block hash from which to retrieve headers (excludes Hash) } 3 BlockHeadersMsg ¶ Header 数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type Header struct { ParentHash common . Hash `json:\"parentHash\" gencodec:\"required\"` UncleHash common . Hash `json:\"sha3Uncles\" gencodec:\"required\"` Coinbase common . Address `json:\"miner\" gencodec:\"required\"` Root common . Hash `json:\"stateRoot\" gencodec:\"required\"` TxHash common . Hash `json:\"transactionsRoot\" gencodec:\"required\"` ReceiptHash common . Hash `json:\"receiptsRoot\" gencodec:\"required\"` Bloom Bloom `json:\"logsBloom\" gencodec:\"required\"` Difficulty * big . Int `json:\"difficulty\" gencodec:\"required\"` Number * big . Int `json:\"number\" gencodec:\"required\"` GasLimit uint64 `json:\"gasLimit\" gencodec:\"required\"` GasUsed uint64 `json:\"gasUsed\" gencodec:\"required\"` Time * big . Int `json:\"timestamp\" gencodec:\"required\"` Extra [] byte `json:\"extraData\" gencodec:\"required\"` MixDigest common . Hash `json:\"mixHash\" gencodec:\"required\"` Nonce BlockNonce `json:\"nonce\" gencodec:\"required\"` } 4 GetBlockBodiesMsg ¶ Hash\b (32 bytes) 数组 5 BlockBodiesMsg ¶ 1 2 // blockBodiesData is the network packet for block content distribution. type blockBodiesData [] * blockBody 1 2 3 4 5 // blockBody represents the data content of a single block. type blockBody struct { Transactions [] * types . Transaction // Transactions contained within a block Uncles [] * types . Header // Uncles contained within a block } 1 2 3 4 5 6 7 type Transaction struct { data txdata // caches hash atomic . Value size atomic . Value from atomic . Value } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 type txdata struct { AccountNonce uint64 `json:\"nonce\" gencodec:\"required\"` Price * big . Int `json:\"gasPrice\" gencodec:\"required\"` GasLimit uint64 `json:\"gas\" gencodec:\"required\"` Recipient * common . Address `json:\"to\" rlp:\"nil\"` // nil means contract creation Amount * big . Int `json:\"value\" gencodec:\"required\"` Payload [] byte `json:\"input\" gencodec:\"required\"` // Signature values V * big . Int `json:\"v\" gencodec:\"required\"` R * big . Int `json:\"r\" gencodec:\"required\"` S * big . Int `json:\"s\" gencodec:\"required\"` // This is only used when marshaling to JSON. Hash * common . Hash `json:\"hash\" rlp:\"-\"` } 6 GetNodeDataMsg ¶ Hash 数组 7 NodeDataMsg ¶ byte 2 维数组 8 GetReceiptsMsg ¶ Hash 数组 9 ReceiptsMsg ¶ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Receipt represents the results of a transaction. type Receipt struct { // Consensus fields PostState [] byte `json:\"root\"` Status uint64 `json:\"status\"` CumulativeGasUsed uint64 `json:\"cumulativeGasUsed\" gencodec:\"required\"` Bloom Bloom `json:\"logsBloom\" gencodec:\"required\"` // 256 bytes Logs [] * Log `json:\"logs\" gencodec:\"required\"` // Implementation fields (don't reorder!) TxHash common . Hash `json:\"transactionHash\" gencodec:\"required\"` ContractAddress common . Address `json:\"contractAddress\"` // 20 bytes GasUsed uint64 `json:\"gasUsed\" gencodec:\"required\"` } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // Log represents a contract log event. These events are generated by the LOG opcode and // stored/indexed by the node. type Log struct { // Consensus fields: // address of the contract that generated the event Address common . Address `json:\"address\" gencodec:\"required\"` // list of topics provided by the contract. Topics [] common . Hash `json:\"topics\" gencodec:\"required\"` // supplied by the contract, usually ABI-encoded Data [] byte `json:\"data\" gencodec:\"required\"` // Derived fields. These fields are filled in by the node // but not secured by consensus. // block in which the transaction was included BlockNumber uint64 `json:\"blockNumber\"` // hash of the transaction TxHash common . Hash `json:\"transactionHash\" gencodec:\"required\"` // index of the transaction in the block TxIndex uint `json:\"transactionIndex\" gencodec:\"required\"` // hash of the block in which the transaction was included BlockHash common . Hash `json:\"blockHash\"` // index of the log in the block Index uint `json:\"logIndex\" gencodec:\"required\"` // The Removed field is true if this log was reverted due to a chain reorganisation. // You must pay attention to this field if you receive logs through a filter query. Removed bool `json:\"removed\"` } 10 NewBlockHashesMsg ¶ 1 2 3 4 5 // newBlockHashesData is the network packet for the block announcements. type newBlockHashesData [] struct { Hash common . Hash // Hash of one particular block being announced Number uint64 // Number of one particular block being announced } 11 NewBlockMsg ¶ 1 2 3 4 type newBlockData struct { Block * types . Block TD * big . Int } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // Block represents an entire block in the Ethereum blockchain. type Block struct { header * Header uncles [] * Header transactions Transactions // caches hash atomic . Value size atomic . Value // Td is used by package core to store the total difficulty // of the chain up to and including the block. td * big . Int // These fields are used by package eth to track // inter-peer block relay. ReceivedAt time . Time ReceivedFrom interface {} } 12 TxMsg ¶ Transaction 数组",
            "title": "通信协议"
        },
        {
            "location": "ethereum/protocal/#_1",
            "text": "",
            "title": "以太坊协议"
        },
        {
            "location": "ethereum/protocal/#1-msg",
            "text": "1 2 3 4 5 6 type Msg struct { Code uint64 Size uint32 // size of the paylod Payload io . Reader ReceivedAt time . Time } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 const ( // Protocol messages belonging to eth/62 StatusMsg = 0x00 NewBlockHashesMsg = 0x01 TxMsg = 0x02 GetBlockHeadersMsg = 0x03 BlockHeadersMsg = 0x04 GetBlockBodiesMsg = 0x05 BlockBodiesMsg = 0x06 NewBlockMsg = 0x07 // Protocol messages belonging to eth/63 GetNodeDataMsg = 0x0d NodeDataMsg = 0x0e GetReceiptsMsg = 0x0f ReceiptsMsg = 0x10 ) Code 相当于 比特币 的 \"command\"，但是明显 \"Code\" 的可扩展性要好的多，但是要求必须都约定好每个数字对应的命令是什么",
            "title": "1 Msg"
        },
        {
            "location": "ethereum/protocal/#2-getblockheaders",
            "text": "1 2 3 4 5 6 7 8 9 10 11 12 type getBlockHeadersData struct { Origin hashOrNumber // Block from which to retrieve headers Amount uint64 // Maximum number of headers to retrieve Skip uint64 // Blocks to skip between consecutive headers Reverse bool // Query direction (false = rising towards latest, true = falling towards genesis) } // hashOrNumber is a combined field for specifying an origin block. type hashOrNumber struct { Hash common . Hash // Block hash from which to retrieve headers (excludes Number) Number uint64 // Block hash from which to retrieve headers (excludes Hash) }",
            "title": "2 GetBlockHeaders"
        },
        {
            "location": "ethereum/protocal/#3-blockheadersmsg",
            "text": "Header 数组 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 type Header struct { ParentHash common . Hash `json:\"parentHash\" gencodec:\"required\"` UncleHash common . Hash `json:\"sha3Uncles\" gencodec:\"required\"` Coinbase common . Address `json:\"miner\" gencodec:\"required\"` Root common . Hash `json:\"stateRoot\" gencodec:\"required\"` TxHash common . Hash `json:\"transactionsRoot\" gencodec:\"required\"` ReceiptHash common . Hash `json:\"receiptsRoot\" gencodec:\"required\"` Bloom Bloom `json:\"logsBloom\" gencodec:\"required\"` Difficulty * big . Int `json:\"difficulty\" gencodec:\"required\"` Number * big . Int `json:\"number\" gencodec:\"required\"` GasLimit uint64 `json:\"gasLimit\" gencodec:\"required\"` GasUsed uint64 `json:\"gasUsed\" gencodec:\"required\"` Time * big . Int `json:\"timestamp\" gencodec:\"required\"` Extra [] byte `json:\"extraData\" gencodec:\"required\"` MixDigest common . Hash `json:\"mixHash\" gencodec:\"required\"` Nonce BlockNonce `json:\"nonce\" gencodec:\"required\"` }",
            "title": "3 BlockHeadersMsg"
        },
        {
            "location": "ethereum/protocal/#4-getblockbodiesmsg",
            "text": "Hash\b (32 bytes) 数组",
            "title": "4 GetBlockBodiesMsg"
        },
        {
            "location": "ethereum/protocal/#5-blockbodiesmsg",
            "text": "1 2 // blockBodiesData is the network packet for block content distribution. type blockBodiesData [] * blockBody 1 2 3 4 5 // blockBody represents the data content of a single block. type blockBody struct { Transactions [] * types . Transaction // Transactions contained within a block Uncles [] * types . Header // Uncles contained within a block } 1 2 3 4 5 6 7 type Transaction struct { data txdata // caches hash atomic . Value size atomic . Value from atomic . Value } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 type txdata struct { AccountNonce uint64 `json:\"nonce\" gencodec:\"required\"` Price * big . Int `json:\"gasPrice\" gencodec:\"required\"` GasLimit uint64 `json:\"gas\" gencodec:\"required\"` Recipient * common . Address `json:\"to\" rlp:\"nil\"` // nil means contract creation Amount * big . Int `json:\"value\" gencodec:\"required\"` Payload [] byte `json:\"input\" gencodec:\"required\"` // Signature values V * big . Int `json:\"v\" gencodec:\"required\"` R * big . Int `json:\"r\" gencodec:\"required\"` S * big . Int `json:\"s\" gencodec:\"required\"` // This is only used when marshaling to JSON. Hash * common . Hash `json:\"hash\" rlp:\"-\"` }",
            "title": "5 BlockBodiesMsg"
        },
        {
            "location": "ethereum/protocal/#6-getnodedatamsg",
            "text": "Hash 数组",
            "title": "6 GetNodeDataMsg"
        },
        {
            "location": "ethereum/protocal/#7-nodedatamsg",
            "text": "byte 2 维数组",
            "title": "7 NodeDataMsg"
        },
        {
            "location": "ethereum/protocal/#8-getreceiptsmsg",
            "text": "Hash 数组",
            "title": "8 GetReceiptsMsg"
        },
        {
            "location": "ethereum/protocal/#9-receiptsmsg",
            "text": "1 2 3 4 5 6 7 8 9 10 11 12 13 14 // Receipt represents the results of a transaction. type Receipt struct { // Consensus fields PostState [] byte `json:\"root\"` Status uint64 `json:\"status\"` CumulativeGasUsed uint64 `json:\"cumulativeGasUsed\" gencodec:\"required\"` Bloom Bloom `json:\"logsBloom\" gencodec:\"required\"` // 256 bytes Logs [] * Log `json:\"logs\" gencodec:\"required\"` // Implementation fields (don't reorder!) TxHash common . Hash `json:\"transactionHash\" gencodec:\"required\"` ContractAddress common . Address `json:\"contractAddress\"` // 20 bytes GasUsed uint64 `json:\"gasUsed\" gencodec:\"required\"` } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // Log represents a contract log event. These events are generated by the LOG opcode and // stored/indexed by the node. type Log struct { // Consensus fields: // address of the contract that generated the event Address common . Address `json:\"address\" gencodec:\"required\"` // list of topics provided by the contract. Topics [] common . Hash `json:\"topics\" gencodec:\"required\"` // supplied by the contract, usually ABI-encoded Data [] byte `json:\"data\" gencodec:\"required\"` // Derived fields. These fields are filled in by the node // but not secured by consensus. // block in which the transaction was included BlockNumber uint64 `json:\"blockNumber\"` // hash of the transaction TxHash common . Hash `json:\"transactionHash\" gencodec:\"required\"` // index of the transaction in the block TxIndex uint `json:\"transactionIndex\" gencodec:\"required\"` // hash of the block in which the transaction was included BlockHash common . Hash `json:\"blockHash\"` // index of the log in the block Index uint `json:\"logIndex\" gencodec:\"required\"` // The Removed field is true if this log was reverted due to a chain reorganisation. // You must pay attention to this field if you receive logs through a filter query. Removed bool `json:\"removed\"` }",
            "title": "9 ReceiptsMsg"
        },
        {
            "location": "ethereum/protocal/#10-newblockhashesmsg",
            "text": "1 2 3 4 5 // newBlockHashesData is the network packet for the block announcements. type newBlockHashesData [] struct { Hash common . Hash // Hash of one particular block being announced Number uint64 // Number of one particular block being announced }",
            "title": "10 NewBlockHashesMsg"
        },
        {
            "location": "ethereum/protocal/#11-newblockmsg",
            "text": "1 2 3 4 type newBlockData struct { Block * types . Block TD * big . Int } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 // Block represents an entire block in the Ethereum blockchain. type Block struct { header * Header uncles [] * Header transactions Transactions // caches hash atomic . Value size atomic . Value // Td is used by package core to store the total difficulty // of the chain up to and including the block. td * big . Int // These fields are used by package eth to track // inter-peer block relay. ReceivedAt time . Time ReceivedFrom interface {} }",
            "title": "11 NewBlockMsg"
        },
        {
            "location": "ethereum/protocal/#12-txmsg",
            "text": "Transaction 数组",
            "title": "12 TxMsg"
        },
        {
            "location": "ethereum/structure/",
            "text": "以太坊数据结构 ¶ 1 以太坊中的序列化方法RLP ¶ RLP(Recursive Length Prefix)可以将任意的数据编码称二进制byte的数组，即[]byte的形式。同时已知数据的RLP编码结果，可以求出其原来的形式 1.1 RLP ¶ RLR 说明 1.2 以太坊中的SHA3计算 ¶ 1 encode(data)=SHA3(RLP(data)) 2 区块的组成 ¶ 2.1 三部分组成 ¶ 区块头（Block Header） 叔块（Uncle） 交易列表（tx_List） 叔块 以太坊每 10 几秒产生一个区块，这样就会有大量的 \"孤块\" 存在。 如果 \"孤块\" 都 不被 承认，可能会有很多计算力小的节点退出，导致以太坊趋于 \"中心化\"，不够安全 \"孤块\" 如何被承认为 \"叔块\" 呢? 就是被之后的 \"新块\" 在打包的时候，包含进去，这样 \"新块\" 被认可的时候，\"叔块\" 也得到了认可。 \"新块\" 为什么会愿意打包 \"叔块\" 呢，因为有奖励 \"叔块\" 的创建者也会有奖励，这样，算力小，网速慢 的一些节点也不会 \"白忙\"，整个系统更 “公平\"，更 \"去中心化\" 2.2 区块头结构 ¶ 名称 类型 意义 parentHash common.Hash \b父区块的哈希值 UncleHash common.Hash 叔父区块列表的哈希值 Coinbase common.Address 打包该区块的矿工的地址，用于接收矿工费 Root common.Hash 状态树的根哈希值 TxHash common.Hash 交易树的根哈希值 ReceiptHash common.Hash \b收据树的根哈希值 Bloom Bloom 交易收据日志组成的Bloom过滤器 Difficuty *Big.Int 本区块的难度 Number *Big.Int 本区块块号，区块号从 0 开始算起 GasLimit uint64 本区块中所有交易消耗的 Gas 上限，这个数值 不等于 所有交易中的 \u001dGasLimit字段的和 GasUsed uint64 本区块中所有交易使用的 Gas 的和 Time *Big.Int 区块产生的 unix 时间戳，一般是打包区块的时间，这个字段不是出块的时间\b戳 Extra []byte 区块的附加数据 MixDigest common.Hash 哈希值，与 Nonce 的组合用于工作量计算 Nonce BlockNonce 区块产生是的随机值 2.3 MPT ¶ 融合了 Merkle Tree，Patricia Tree (源于 Trie Tree) 2.3.1 4 种节点 ¶ fullNode shorNode valueNode hashNode fullNode fullNode 是一个可以携带多个子节点的父(枝)节点。 它有一个容量为17的node数组成员变量Children，数组中前16个空位分别对应16进制(hex)下的0-9a-f，这样对于每个子节点，根据其key值16进制形式下的第一位的值，就可挂载到Children数组的某个位置。 fullNode本身不再需要额外key变量。 Children数组的第17位，留给该fullNode的数据部分。 fullNode明显继承了原生trie的特点，而每个父节点最多拥有16个分支也包含了基于总体效率的考量 shorNode shortNode 是一个仅有一个子节点的父(枝)节点。 它的成员变量Val指向一个子节点，而成员Key是一个任意长度的字符串(字节数组[]byte)。 显然shortNode的设计体现了PatriciaTrie的特点，通过合并只有一个子节点的父节点和其子节点来缩短trie的深度，结果就是有些节点会有长度更长的key。 valueNode valueNode 充当MPT的叶子节点。 它其实是字节数组[]byte的一个别名，不带子节点。 在使用中，valueNode就是所携带数据部分的RLP哈希值，长度32byte，数据的RLP编码值作为valueNode的匹配项存储在数据库里。 hashNode hashNode 跟valueNode一样，也是字符数组[]byte的一个别名，同样存放32byte的哈希值，也没有子节点。 不同的是，hashNode是fullNode或者shortNode对象的RLP哈希值，所以它跟valueNode在使用上有着莫大的不同。",
            "title": "结构"
        },
        {
            "location": "ethereum/structure/#_1",
            "text": "",
            "title": "以太坊数据结构"
        },
        {
            "location": "ethereum/structure/#1-rlp",
            "text": "RLP(Recursive Length Prefix)可以将任意的数据编码称二进制byte的数组，即[]byte的形式。同时已知数据的RLP编码结果，可以求出其原来的形式",
            "title": "1 以太坊中的序列化方法RLP"
        },
        {
            "location": "ethereum/structure/#11-rlp",
            "text": "RLR 说明",
            "title": "1.1 RLP"
        },
        {
            "location": "ethereum/structure/#12-sha3",
            "text": "1 encode(data)=SHA3(RLP(data))",
            "title": "1.2 以太坊中的SHA3计算"
        },
        {
            "location": "ethereum/structure/#2",
            "text": "",
            "title": "2 区块的组成"
        },
        {
            "location": "ethereum/structure/#21",
            "text": "区块头（Block Header） 叔块（Uncle） 交易列表（tx_List） 叔块 以太坊每 10 几秒产生一个区块，这样就会有大量的 \"孤块\" 存在。 如果 \"孤块\" 都 不被 承认，可能会有很多计算力小的节点退出，导致以太坊趋于 \"中心化\"，不够安全 \"孤块\" 如何被承认为 \"叔块\" 呢? 就是被之后的 \"新块\" 在打包的时候，包含进去，这样 \"新块\" 被认可的时候，\"叔块\" 也得到了认可。 \"新块\" 为什么会愿意打包 \"叔块\" 呢，因为有奖励 \"叔块\" 的创建者也会有奖励，这样，算力小，网速慢 的一些节点也不会 \"白忙\"，整个系统更 “公平\"，更 \"去中心化\"",
            "title": "2.1 三部分组成"
        },
        {
            "location": "ethereum/structure/#22",
            "text": "名称 类型 意义 parentHash common.Hash \b父区块的哈希值 UncleHash common.Hash 叔父区块列表的哈希值 Coinbase common.Address 打包该区块的矿工的地址，用于接收矿工费 Root common.Hash 状态树的根哈希值 TxHash common.Hash 交易树的根哈希值 ReceiptHash common.Hash \b收据树的根哈希值 Bloom Bloom 交易收据日志组成的Bloom过滤器 Difficuty *Big.Int 本区块的难度 Number *Big.Int 本区块块号，区块号从 0 开始算起 GasLimit uint64 本区块中所有交易消耗的 Gas 上限，这个数值 不等于 所有交易中的 \u001dGasLimit字段的和 GasUsed uint64 本区块中所有交易使用的 Gas 的和 Time *Big.Int 区块产生的 unix 时间戳，一般是打包区块的时间，这个字段不是出块的时间\b戳 Extra []byte 区块的附加数据 MixDigest common.Hash 哈希值，与 Nonce 的组合用于工作量计算 Nonce BlockNonce 区块产生是的随机值",
            "title": "2.2 区块头结构"
        },
        {
            "location": "ethereum/structure/#23-mpt",
            "text": "融合了 Merkle Tree，Patricia Tree (源于 Trie Tree)",
            "title": "2.3 MPT"
        },
        {
            "location": "ethereum/structure/#231-4",
            "text": "fullNode shorNode valueNode hashNode fullNode fullNode 是一个可以携带多个子节点的父(枝)节点。 它有一个容量为17的node数组成员变量Children，数组中前16个空位分别对应16进制(hex)下的0-9a-f，这样对于每个子节点，根据其key值16进制形式下的第一位的值，就可挂载到Children数组的某个位置。 fullNode本身不再需要额外key变量。 Children数组的第17位，留给该fullNode的数据部分。 fullNode明显继承了原生trie的特点，而每个父节点最多拥有16个分支也包含了基于总体效率的考量 shorNode shortNode 是一个仅有一个子节点的父(枝)节点。 它的成员变量Val指向一个子节点，而成员Key是一个任意长度的字符串(字节数组[]byte)。 显然shortNode的设计体现了PatriciaTrie的特点，通过合并只有一个子节点的父节点和其子节点来缩短trie的深度，结果就是有些节点会有长度更长的key。 valueNode valueNode 充当MPT的叶子节点。 它其实是字节数组[]byte的一个别名，不带子节点。 在使用中，valueNode就是所携带数据部分的RLP哈希值，长度32byte，数据的RLP编码值作为valueNode的匹配项存储在数据库里。 hashNode hashNode 跟valueNode一样，也是字符数组[]byte的一个别名，同样存放32byte的哈希值，也没有子节点。 不同的是，hashNode是fullNode或者shortNode对象的RLP哈希值，所以它跟valueNode在使用上有着莫大的不同。",
            "title": "2.3.1 4 种节点"
        },
        {
            "location": "ethereum/sync/",
            "text": "数据同步 ¶ 1 \b被动同步 ¶ 被动同步由fetcher完成，被动模式又分为两种 1. 收到blockhash广播消息(NewBlockHashesMsg) 2. 收到完整的block广播消息(NewBlockMsg) 1.1 NewBlockHashesMsg 被动模式 ¶ sequenceDiagram participant pm as ProtocalManager participant ft as Fetcher participant rp as Remote Peer rp ->> pm: 1: NewBlockHashesMsg pm ->> ft: 2: f.notify ft ->> ft: 3: fetchTimer.C Note right of ft: f.announced ft ->> rp: 4: fetchHeader Note right of ft: f.fetching rp -->> pm: 5: BlockHeadersMsg pm ->> ft: 6:FilterHeaders ft ->> ft: 7: f.headerFilter Note right of ft: f.fetched ft ->> ft: 8: completeTimer.C Note right of ft: f.completing ft ->> rp: 9: fetchBodies rp -->> pm: 10: BlockBodiesMsg pm ->> ft: 11: FilterBodies ft ->> ft: 12: f.bodyFilter Note right of ft: f.queue ft ->> ft: 13: Loop_queue ft ->> ft: 14: insert 1.1.1 过程描述 ¶ 收到外部节点NewBlockHashesMsg消息，确定本地没有，然后发送一个announce给fetcher fetcher 循环处理收到的消息，header 消息放到 f.fetching (正在获取中) 里，按要求发出 fetchHeader 远端收到 fetchHeader 消息会发出 BlockHeadersMsg 收到 header 消息后，检查是否需要获取 body 如果需要，发出 fetchBodies 消息 远端回复 BlockBodiesMsg 得到 body 数据，验证，存储 1.2 NewBlockMsg 被动模式 ¶ sequenceDiagram participant pm as ProtocalManager participant ft as Fetcher participant rp as Remote Peer rp ->> pm: 1: NewBlogMsg pm ->> ft: 2: Enqueue ft ->> ft: 3: inject ft ->> ft: 4: enqueue ft ->> ft: 5: Loop_queue ft ->> ft: 6: insert 1.2.1 过程描述 ¶ NewBlockHashesMsg 模式的简化 2 主动同步 ¶ 2.1 主动同步的主要场景 ¶ geth刚启动 新peer加入 定时sync 2.2 查找通信节点主链共同祖先 ¶ 比特币是将本地chain顶端N个block的hash及后续以1/2跳跃的方式得到m个block的hash(blocklocator)发送给外部节点，这样外部节点能轻松的找到两个节点的链的共同祖先 以太币不一样，它分两个步骤来操作，第一步是向外部节点请求N个block的hash并和本地对比找到共同祖先，如果第一步没有找到祖先，则按照类似1/2跳跃的方式循环请求更前面的区块的hash，并和本地对比来找到共同祖先 可见两种方式的核心区别是，比特币是主动提供本地链区块头信息，外部节点负责找出祖先，而以太币是从外部节点获取数据，本地负责找出祖先。如果共同祖先大部分都是在前N个区块，这两种方式差不多，但是如果进行到1/2跳跃请求，则以太坊的请求次数明显增多。",
            "title": "同步"
        },
        {
            "location": "ethereum/sync/#_1",
            "text": "",
            "title": "数据同步"
        },
        {
            "location": "ethereum/sync/#1",
            "text": "被动同步由fetcher完成，被动模式又分为两种 1. 收到blockhash广播消息(NewBlockHashesMsg) 2. 收到完整的block广播消息(NewBlockMsg)",
            "title": "1 \b被动同步"
        },
        {
            "location": "ethereum/sync/#11-newblockhashesmsg",
            "text": "sequenceDiagram participant pm as ProtocalManager participant ft as Fetcher participant rp as Remote Peer rp ->> pm: 1: NewBlockHashesMsg pm ->> ft: 2: f.notify ft ->> ft: 3: fetchTimer.C Note right of ft: f.announced ft ->> rp: 4: fetchHeader Note right of ft: f.fetching rp -->> pm: 5: BlockHeadersMsg pm ->> ft: 6:FilterHeaders ft ->> ft: 7: f.headerFilter Note right of ft: f.fetched ft ->> ft: 8: completeTimer.C Note right of ft: f.completing ft ->> rp: 9: fetchBodies rp -->> pm: 10: BlockBodiesMsg pm ->> ft: 11: FilterBodies ft ->> ft: 12: f.bodyFilter Note right of ft: f.queue ft ->> ft: 13: Loop_queue ft ->> ft: 14: insert",
            "title": "1.1 NewBlockHashesMsg 被动模式"
        },
        {
            "location": "ethereum/sync/#111",
            "text": "收到外部节点NewBlockHashesMsg消息，确定本地没有，然后发送一个announce给fetcher fetcher 循环处理收到的消息，header 消息放到 f.fetching (正在获取中) 里，按要求发出 fetchHeader 远端收到 fetchHeader 消息会发出 BlockHeadersMsg 收到 header 消息后，检查是否需要获取 body 如果需要，发出 fetchBodies 消息 远端回复 BlockBodiesMsg 得到 body 数据，验证，存储",
            "title": "1.1.1 过程描述"
        },
        {
            "location": "ethereum/sync/#12-newblockmsg",
            "text": "sequenceDiagram participant pm as ProtocalManager participant ft as Fetcher participant rp as Remote Peer rp ->> pm: 1: NewBlogMsg pm ->> ft: 2: Enqueue ft ->> ft: 3: inject ft ->> ft: 4: enqueue ft ->> ft: 5: Loop_queue ft ->> ft: 6: insert",
            "title": "1.2 NewBlockMsg 被动模式"
        },
        {
            "location": "ethereum/sync/#121",
            "text": "NewBlockHashesMsg 模式的简化",
            "title": "1.2.1 过程描述"
        },
        {
            "location": "ethereum/sync/#2",
            "text": "",
            "title": "2 主动同步"
        },
        {
            "location": "ethereum/sync/#21",
            "text": "geth刚启动 新peer加入 定时sync",
            "title": "2.1 主动同步的主要场景"
        },
        {
            "location": "ethereum/sync/#22",
            "text": "比特币是将本地chain顶端N个block的hash及后续以1/2跳跃的方式得到m个block的hash(blocklocator)发送给外部节点，这样外部节点能轻松的找到两个节点的链的共同祖先 以太币不一样，它分两个步骤来操作，第一步是向外部节点请求N个block的hash并和本地对比找到共同祖先，如果第一步没有找到祖先，则按照类似1/2跳跃的方式循环请求更前面的区块的hash，并和本地对比来找到共同祖先 可见两种方式的核心区别是，比特币是主动提供本地链区块头信息，外部节点负责找出祖先，而以太币是从外部节点获取数据，本地负责找出祖先。如果共同祖先大部分都是在前N个区块，这两种方式差不多，但是如果进行到1/2跳跃请求，则以太坊的请求次数明显增多。",
            "title": "2.2 查找通信节点主链共同祖先"
        },
        {
            "location": "trias/datastore/",
            "text": "\bTrias 数据存储 ¶ 1. 两个概念 ¶ 1.1 条目 ¶ 以往的区块链如\b比特币，以太坊，块体里面的结构的格式是固定的。不管是 UTXO 的形式，还是智能合约的形式，\b格式上都是已经约定好的。为了能够在数据保存上处理的更加灵活，我们提出条目的概念。区块体中存储着的是\b条目的集合。 1.1.1 什么是条目 ¶ 条目是一个很宽泛的概念。它是一个格式\b自解释的数据块，是各种交易形式的一种抽象。\b格式如下: 大小(字节) 名称 数据类型 描述 4 itemType uint32 类型 varint payloadSize uint32 \b载荷大小 varies payload []byte 载荷 对每一种类型，payload 都对应着不同的结构。 1.1.2 条目的优点 ¶ 不管是 UTXO 的形式，还是智能合约的形式，只要定义好了结构和相应的解析逻辑，把它们作为条目的 payload 部分，从外面看都是一个条目，这就为不同的业务逻辑存储成相同形式带来了可能。 如果现有的数据格式不足以满足新增的业务逻辑，那么可以定义新的数据格式，并定义对应的 itemType，如果已有的格式需要更新，也可以定义\b基于原来格式的新格式，\b毕竟区块链的数据是不能篡改的，同时，\b这也符合了面向对象设计中的 \"对修改关闭，对扩展开放\" 的开闭原则。使系统可以向后兼容。 1.2 文件仓库 ¶ 比特币，超级账本中都是以区块为单位，多个区块保存到一个区块文件中。EOS 在与 IPFS 的结合中，把交易保存成文件，区块中保存了对交易的引用。显然 EOS 的做法，更加灵活。因为各交易被打包到一个区块中，只是时间相近，所以在存储中物理相邻，它们多数情况下并没有逻辑上的必然联系。所以我们提出文件仓库的概念，主要用来存储条目(也有其他文件，如\b状态文件等)，一个条目一个文件，区块中只保留文件的索引，索引有可能是 IPFS 的 FileId，或其他。 1.2.1 为什么不直接用 IPFS，还要提出文件仓库 ¶ 文件仓库是一个抽象，\bIPFS 只是真实存储文件的方式之一，我们可以使用 IPFS，也可以使用其他类似系统，甚至自己实现，或是几种方式的结合。对于想要获取条目内容的节点来说，可以不必关心实现方式。同时，为今后系统的扩容带来了更多的选择。 1.2.2 为什么不存储区块文件，而是存储条目文件 ¶ 如前面所说，多个条目逻辑上很可能没有任何关系，假设一个节点想要获取某个条目的内容，而首先获取了整个区块，然后再进行解析，势必加大了无效的数据传输，而影响了系统性能。 1.2.3 仓库文件索引 ¶ \b仓库文件索引是独立于第三方系统的文件唯一标识，不等同于 IPFS 的 FileId，假如我们使用 IPFS 来存储文件，那么需要维护一个仓库文件索引与 IPFS 的\b FileId 的映射关系。 1. 存储结构 ¶ 1.1 文件系统 ¶ \b文件系统用来存储区块数据，状态数据，历史数据，\b以二进制数据文件或文本文件来存储。 1.1 文件存储的优势 ¶ 不受平台影响(操作系统) 不需要更多\b依赖(相对于数据库来说) 便于与 IPFS 这种去中心化文件系统进行对接 适当的\b对文件大小进行规划，对文件进行组织，便于传播 1.2 基础数据结构 ¶ 1.2.1 \bBlock ¶ 大小(字节) 名称 数据类型 描述 4 magicNumber uint32 值 待定, 作为区块之间的分隔符 4 blockSize uint32 后面数据到块结束的字节数 68 blockHeader []byte 块头 (大小待定) varint itemCount uint64 条目数量 varies itemIndex [32]byte 条目索引集合 1.2.2 Header ¶ 大小(字节) 名称 数据类型 描述 4 version uint32 版本号 32 previous_block_hash [32]byte 前一个 block 的 \bhash 值 32 merkle_root_hash [32]byte 区块内所有 Item 的 merkle_hash 值 Header 中的其他项待定 \b比如比特币中的 Hash 难度值，计算用的随机数 Nonce 跟共识算法相关，这里待定 1.2.3 条目 ¶ 条目 (Item) 条目 是一个宽泛的概念，它可以是类似比特币的交易，也可以是类似以太坊的交易，这样可以带来两个好处： 使得账号状态，UTXO 两种不同机制的数据可以共存 对已有结构进行改进，可以重新定义一个 itemType 及其解释方式 1.2 索引系统 ¶ 用来快速定位存储内容。通过索引可以快速定位到 Block，Item (各种交易或其他数据形式)，以及 Item 当中子项。索引系统使用 levelDB。 2 节点分工 ¶ 2.1 全节点 ¶ 存放区块文件，状态文件 验证 上传条目文件到 文件仓库 缓存部分条目 Note IPFS 只负责存储文件，并不参与业务逻辑，如何解析文件内容，还需要全节点来负责。 IPFS 的 FileId 虽然也是内容哈希，但与区块哈希的计算\b规则并不相同，所以需要保存映射关系 2.2 轻节点 ¶ 存放所有条目哈希，\b在接到客户节点交易请求时可根据条目哈希从全节点获取条目数据，进行验证 按照客户节点的交易请求形成条目 部分验证 打包区块，上传给全节点 2.3 \b客户节点 ¶ 保存与本节点相关的信息，最大化\b减少数据存储量，增强客户节点的可用性 3 同步 ¶ 3.1 被动同步 ¶ 3.1.1 被动同步时机 ¶ 3.1.1.1 \bNewBlockHashMsg ¶ 全节点 sequenceDiagram participant L as Local FullNode participant P as Peer FullNode P ->> L: NewBlockHashMsg L ->> L: CheckHashExist L ->> P: GetBlockMsg P -->> L: BlockMsg L ->> L: SaveBlock Send NewBlockHashMsg 过程描述: Peer FullNode 在存入新区块，或获取新区块之后 发出 NewBlockHashMsg Local FullNode 获取到 NewBlockHashMsg，在本地进行对比，若不存在，则发出 GetBlockMsg 给 Peer FullNode Peer FullNode 获取到 GetBlockMsg 后，从本地查询并通过 BlockMsg 将 Block 信息发送给 Local FullNode Local FullNode 在拿到 Block 信息之后，计算 Block，Item 等信息的索引，并将 Block，相关索引保存 轻节点 sequenceDiagram participant L as Local LightNode participant P as Peer FullNode P ->> L: NewBlockHashMsg L ->> L: CheckHashExist L ->> P: GetBlockHashMsg P -->> L: BlockHashMsg L ->> L: SaveHash SaveItemHash 过程描述: Peer FullNode 在存入区块，或获取新区块之后 发出 NewBlockHashMsg Local LightNode 获取到 NewBlockHashMsg，在本地进行对比，若不存在，则发出 GetBlockHashMsg 给 Peer FullNode Peer FullNode 通过 BlockHashMsg 将 BlockHash, ItemHash 等信息发送给 Local ClientNode Local ClientNode 保存 BlockHash, ItemHash 等信息 BlockHashMsg \bBlockHashMsg 会包含区块当中的 条目 \bHash 3.2 主动同步 ¶ 3.2.1 主动同步时机 ¶ 3.2.1.1 新节点加入 ¶ 全节点 sequenceDiagram participant L as Local FullNode participant P as Peer FullNode L ->> P: GetHeaderHashMsg P -->> L: HeaderHashMsg L ->> P: GetBlockMsg P -->> L: BlockMsg L ->> L: SaveBlock 过程描述: 当一个新的全节点加入，会循环向其他 FullNode 发出 GetHeaderHashMsg 远端 FullNode 发送 HeaderHashMsg 给本节点 本节点根据 HeaderHash 向远端节点 发出 GetBlockMsg 远端 FullNode 发送 BlockMsg 给本节点 \b本节点进行数据保存 轻节点 sequenceDiagram participant L as Local LightNode participant P as Peer LightNode L ->> P: GetHeaderHashMsg P -->> L: HeaderHashMsg L ->> L: SaveHash 过程描述: 当一个新的全节点加入，会循环向其他 FullNode 发出 GetHeaderHashMsg 远端 FullNode 发送 HeaderHashMsg 给本节点 \b本节点进行数据保存",
            "title": "数据层"
        },
        {
            "location": "trias/datastore/#trias",
            "text": "",
            "title": "\bTrias 数据存储"
        },
        {
            "location": "trias/datastore/#1",
            "text": "",
            "title": "1. 两个概念"
        },
        {
            "location": "trias/datastore/#11",
            "text": "以往的区块链如\b比特币，以太坊，块体里面的结构的格式是固定的。不管是 UTXO 的形式，还是智能合约的形式，\b格式上都是已经约定好的。为了能够在数据保存上处理的更加灵活，我们提出条目的概念。区块体中存储着的是\b条目的集合。",
            "title": "1.1 条目"
        },
        {
            "location": "trias/datastore/#111",
            "text": "条目是一个很宽泛的概念。它是一个格式\b自解释的数据块，是各种交易形式的一种抽象。\b格式如下: 大小(字节) 名称 数据类型 描述 4 itemType uint32 类型 varint payloadSize uint32 \b载荷大小 varies payload []byte 载荷 对每一种类型，payload 都对应着不同的结构。",
            "title": "1.1.1 什么是条目"
        },
        {
            "location": "trias/datastore/#112",
            "text": "不管是 UTXO 的形式，还是智能合约的形式，只要定义好了结构和相应的解析逻辑，把它们作为条目的 payload 部分，从外面看都是一个条目，这就为不同的业务逻辑存储成相同形式带来了可能。 如果现有的数据格式不足以满足新增的业务逻辑，那么可以定义新的数据格式，并定义对应的 itemType，如果已有的格式需要更新，也可以定义\b基于原来格式的新格式，\b毕竟区块链的数据是不能篡改的，同时，\b这也符合了面向对象设计中的 \"对修改关闭，对扩展开放\" 的开闭原则。使系统可以向后兼容。",
            "title": "1.1.2 条目的优点"
        },
        {
            "location": "trias/datastore/#12",
            "text": "比特币，超级账本中都是以区块为单位，多个区块保存到一个区块文件中。EOS 在与 IPFS 的结合中，把交易保存成文件，区块中保存了对交易的引用。显然 EOS 的做法，更加灵活。因为各交易被打包到一个区块中，只是时间相近，所以在存储中物理相邻，它们多数情况下并没有逻辑上的必然联系。所以我们提出文件仓库的概念，主要用来存储条目(也有其他文件，如\b状态文件等)，一个条目一个文件，区块中只保留文件的索引，索引有可能是 IPFS 的 FileId，或其他。",
            "title": "1.2 文件仓库"
        },
        {
            "location": "trias/datastore/#121-ipfs",
            "text": "文件仓库是一个抽象，\bIPFS 只是真实存储文件的方式之一，我们可以使用 IPFS，也可以使用其他类似系统，甚至自己实现，或是几种方式的结合。对于想要获取条目内容的节点来说，可以不必关心实现方式。同时，为今后系统的扩容带来了更多的选择。",
            "title": "1.2.1 为什么不直接用 IPFS，还要提出文件仓库"
        },
        {
            "location": "trias/datastore/#122",
            "text": "如前面所说，多个条目逻辑上很可能没有任何关系，假设一个节点想要获取某个条目的内容，而首先获取了整个区块，然后再进行解析，势必加大了无效的数据传输，而影响了系统性能。",
            "title": "1.2.2 为什么不存储区块文件，而是存储条目文件"
        },
        {
            "location": "trias/datastore/#123",
            "text": "\b仓库文件索引是独立于第三方系统的文件唯一标识，不等同于 IPFS 的 FileId，假如我们使用 IPFS 来存储文件，那么需要维护一个仓库文件索引与 IPFS 的\b FileId 的映射关系。",
            "title": "1.2.3 仓库文件索引"
        },
        {
            "location": "trias/datastore/#1_1",
            "text": "",
            "title": "1. 存储结构"
        },
        {
            "location": "trias/datastore/#11_1",
            "text": "\b文件系统用来存储区块数据，状态数据，历史数据，\b以二进制数据文件或文本文件来存储。",
            "title": "1.1 文件系统"
        },
        {
            "location": "trias/datastore/#11_2",
            "text": "不受平台影响(操作系统) 不需要更多\b依赖(相对于数据库来说) 便于与 IPFS 这种去中心化文件系统进行对接 适当的\b对文件大小进行规划，对文件进行组织，便于传播",
            "title": "1.1 文件存储的优势"
        },
        {
            "location": "trias/datastore/#12_1",
            "text": "",
            "title": "1.2 基础数据结构"
        },
        {
            "location": "trias/datastore/#121-block",
            "text": "大小(字节) 名称 数据类型 描述 4 magicNumber uint32 值 待定, 作为区块之间的分隔符 4 blockSize uint32 后面数据到块结束的字节数 68 blockHeader []byte 块头 (大小待定) varint itemCount uint64 条目数量 varies itemIndex [32]byte 条目索引集合",
            "title": "1.2.1 \bBlock"
        },
        {
            "location": "trias/datastore/#122-header",
            "text": "大小(字节) 名称 数据类型 描述 4 version uint32 版本号 32 previous_block_hash [32]byte 前一个 block 的 \bhash 值 32 merkle_root_hash [32]byte 区块内所有 Item 的 merkle_hash 值 Header 中的其他项待定 \b比如比特币中的 Hash 难度值，计算用的随机数 Nonce 跟共识算法相关，这里待定",
            "title": "1.2.2 Header"
        },
        {
            "location": "trias/datastore/#123_1",
            "text": "条目 (Item) 条目 是一个宽泛的概念，它可以是类似比特币的交易，也可以是类似以太坊的交易，这样可以带来两个好处： 使得账号状态，UTXO 两种不同机制的数据可以共存 对已有结构进行改进，可以重新定义一个 itemType 及其解释方式",
            "title": "1.2.3 条目"
        },
        {
            "location": "trias/datastore/#12_2",
            "text": "用来快速定位存储内容。通过索引可以快速定位到 Block，Item (各种交易或其他数据形式)，以及 Item 当中子项。索引系统使用 levelDB。",
            "title": "1.2 索引系统"
        },
        {
            "location": "trias/datastore/#2",
            "text": "",
            "title": "2 节点分工"
        },
        {
            "location": "trias/datastore/#21",
            "text": "存放区块文件，状态文件 验证 上传条目文件到 文件仓库 缓存部分条目 Note IPFS 只负责存储文件，并不参与业务逻辑，如何解析文件内容，还需要全节点来负责。 IPFS 的 FileId 虽然也是内容哈希，但与区块哈希的计算\b规则并不相同，所以需要保存映射关系",
            "title": "2.1 全节点"
        },
        {
            "location": "trias/datastore/#22",
            "text": "存放所有条目哈希，\b在接到客户节点交易请求时可根据条目哈希从全节点获取条目数据，进行验证 按照客户节点的交易请求形成条目 部分验证 打包区块，上传给全节点",
            "title": "2.2 轻节点"
        },
        {
            "location": "trias/datastore/#23",
            "text": "保存与本节点相关的信息，最大化\b减少数据存储量，增强客户节点的可用性",
            "title": "2.3 \b客户节点"
        },
        {
            "location": "trias/datastore/#3",
            "text": "",
            "title": "3 同步"
        },
        {
            "location": "trias/datastore/#31",
            "text": "",
            "title": "3.1 被动同步"
        },
        {
            "location": "trias/datastore/#311",
            "text": "",
            "title": "3.1.1 被动同步时机"
        },
        {
            "location": "trias/datastore/#3111-newblockhashmsg",
            "text": "全节点 sequenceDiagram participant L as Local FullNode participant P as Peer FullNode P ->> L: NewBlockHashMsg L ->> L: CheckHashExist L ->> P: GetBlockMsg P -->> L: BlockMsg L ->> L: SaveBlock Send NewBlockHashMsg 过程描述: Peer FullNode 在存入新区块，或获取新区块之后 发出 NewBlockHashMsg Local FullNode 获取到 NewBlockHashMsg，在本地进行对比，若不存在，则发出 GetBlockMsg 给 Peer FullNode Peer FullNode 获取到 GetBlockMsg 后，从本地查询并通过 BlockMsg 将 Block 信息发送给 Local FullNode Local FullNode 在拿到 Block 信息之后，计算 Block，Item 等信息的索引，并将 Block，相关索引保存 轻节点 sequenceDiagram participant L as Local LightNode participant P as Peer FullNode P ->> L: NewBlockHashMsg L ->> L: CheckHashExist L ->> P: GetBlockHashMsg P -->> L: BlockHashMsg L ->> L: SaveHash SaveItemHash 过程描述: Peer FullNode 在存入区块，或获取新区块之后 发出 NewBlockHashMsg Local LightNode 获取到 NewBlockHashMsg，在本地进行对比，若不存在，则发出 GetBlockHashMsg 给 Peer FullNode Peer FullNode 通过 BlockHashMsg 将 BlockHash, ItemHash 等信息发送给 Local ClientNode Local ClientNode 保存 BlockHash, ItemHash 等信息 BlockHashMsg \bBlockHashMsg 会包含区块当中的 条目 \bHash",
            "title": "3.1.1.1 \bNewBlockHashMsg"
        },
        {
            "location": "trias/datastore/#32",
            "text": "",
            "title": "3.2 主动同步"
        },
        {
            "location": "trias/datastore/#321",
            "text": "",
            "title": "3.2.1 主动同步时机"
        },
        {
            "location": "trias/datastore/#3211",
            "text": "全节点 sequenceDiagram participant L as Local FullNode participant P as Peer FullNode L ->> P: GetHeaderHashMsg P -->> L: HeaderHashMsg L ->> P: GetBlockMsg P -->> L: BlockMsg L ->> L: SaveBlock 过程描述: 当一个新的全节点加入，会循环向其他 FullNode 发出 GetHeaderHashMsg 远端 FullNode 发送 HeaderHashMsg 给本节点 本节点根据 HeaderHash 向远端节点 发出 GetBlockMsg 远端 FullNode 发送 BlockMsg 给本节点 \b本节点进行数据保存 轻节点 sequenceDiagram participant L as Local LightNode participant P as Peer LightNode L ->> P: GetHeaderHashMsg P -->> L: HeaderHashMsg L ->> L: SaveHash 过程描述: 当一个新的全节点加入，会循环向其他 FullNode 发出 GetHeaderHashMsg 远端 FullNode 发送 HeaderHashMsg 给本节点 \b本节点进行数据保存",
            "title": "3.2.1.1 新节点加入"
        }
    ]
}